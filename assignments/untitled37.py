# -*- coding: utf-8 -*-
"""Untitled37.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12OcyXiv5Rw3VUQrW0B1SX7RESdEKK9b8
"""

# %% [markdown]
# # Assignment 3
#
# Deadline: 09.04.2025 12:00 CET
#
# <Add your name, student-id and emal address>

# %%
# Standard library imports
import os
import sys
import types

# Third party imports
import numpy as np
import pandas as pd

# Add the project root directory to Python path
project_root = "/Users/eleonorasalcuni"  #<Change this path if needed>
src_path = os.path.join(project_root, 'qpmwp-course/src')
sys.path.append(project_root)
sys.path.append(src_path)

# Local modules imports
from helper_functions import load_data_msci
from estimation.covariance import Covariance
from estimation.expected_return import ExpectedReturn
from optimization.optimization import MeanVariance
from backtesting.backtest_item_builder_classes import (
    SelectionItemBuilder,
    OptimizationItemBuilder,
)
from backtesting.backtest_item_builder_functions import (
    bibfn_selection_data_random,
    bibfn_return_series,
    bibfn_budget_constraint,
    bibfn_box_constraints,
)
from backtesting.portfolio import floating_weights
from backtesting.backtest_service import BacktestService
from backtesting.backtest import Backtest

# %% [markdown]
# ### Data load

# %%
N = 24
data = load_data_msci(path = '/Users/eleonorasalcuni/Desktop/Master Finance/qpmwp-course/data/', n = N)

# %% [markdown]
# ### Prepare backtest service

# %%
# Define rebalancing dates
n_days = 21 * 3
start_date = '2010-01-01'
dates = data['return_series'].index
rebdates = dates[dates > start_date][::n_days].strftime('%Y-%m-%d').tolist()

# Define the selection item builders.
selection_item_builders = {
    'data': SelectionItemBuilder(
        bibfn = bibfn_selection_data_random,
        k = 10,
        seed = 42,
    ),
}

# Define the optimization item builders.
optimization_item_builders = {
    'return_series': OptimizationItemBuilder(
        bibfn = bibfn_return_series,
        width = 365 * 3,
    ),
    'budget_constraint': OptimizationItemBuilder(
        bibfn = bibfn_budget_constraint,
        budget = 1,
    ),
    'box_constraints': OptimizationItemBuilder(
        bibfn = bibfn_box_constraints,
        upper = 0.5,
    ),
}

# Initialize the backtest service
bs = BacktestService(
    data = data,
    selection_item_builders = selection_item_builders,
    optimization_item_builders = optimization_item_builders,
    optimization = MeanVariance(
        covariance = Covariance(method = 'pearson'),
        expected_return = ExpectedReturn(method = 'geometric'),
        risk_aversion = 1,
        solver_name = 'cvxopt',
    ),
    rebdates = rebdates,
)

# %% [markdown]
# ### Run the backtest

# %%
# Instantiate the backtest object and run the backtest
bt_mv = Backtest()

# Run the backtest
bt_mv.run(bs = bs)

# %% [markdown]
# ## 1. Turnover
#
# **(6 points)**
#
# Complete the function `turnover`.

# %%
def turnover(self, return_series: pd.DataFrame, rescale: bool=True):
    """
    Calculate portfolio turnover at each rebalancing date.

    Parameters:
    -----------
    return_series : pd.DataFrame
        Asset returns indexed by dates
    rescale : bool, default=True
        Whether to rescale weights when floating

    Returns:
    --------
    pd.Series
        Turnover at each rebalancing date
    """
    dates = self.get_rebalancing_dates()
    to = {}
    to[dates[0]] = float(1)  # Turnover is 1 at the initial date

    for rebalancing_date in dates[1:]:
        previous_portfolio = self.get_previous_portfolio(rebalancing_date)
        current_portfolio = self.get_portfolio(rebalancing_date)

        if current_portfolio.rebalancing_date is None or previous_portfolio.rebalancing_date is None:
            raise ValueError('Portfolios must have a rebalancing date')

        if current_portfolio.rebalancing_date < previous_portfolio.rebalancing_date:
            raise ValueError('The previous portfolio must be older than the current portfolio')

        # Get the weights - convert to pandas Series if they're dictionaries
        prev_weights = pd.Series(previous_portfolio.weights) if isinstance(previous_portfolio.weights, dict) else previous_portfolio.weights
        curr_weights = pd.Series(current_portfolio.weights) if isinstance(current_portfolio.weights, dict) else current_portfolio.weights

        # Get the union of the ids of the weights in both portfolios
        union_ids = set(prev_weights.index).union(set(curr_weights.index))

        # Extend the weights of the previous portfolio to the union of ids by adding zeros where needed
        prev_weights = prev_weights.reindex(union_ids, fill_value=0)

        # Define our own floating_weights function
        def float_weights(weights, returns, rescale=True):
            """
            Float portfolio weights according to price drifts in the market.

            Parameters:
            -----------
            weights : pd.Series
                Initial portfolio weights indexed by asset IDs
            returns : pd.DataFrame
                Asset returns between the previous rebalancing date and current date
            rescale : bool, default=True
                Whether to rescale weights to sum to 1 after floating

            Returns:
            --------
            pd.Series
                Floated weights indexed by asset IDs
            """
            # Create a copy of the input weights to avoid modifying the original
            result = weights.copy()

            # We only need to process assets that have weight > 0
            assets_to_process = result.index[result > 0]

            # For each date in the return series (in chronological order)
            for date in returns.index:
                returns_at_date = returns.loc[date]

                # Update each weight based on its return
                for asset in assets_to_process:
                    if asset in returns_at_date:
                        # Adjust weight by the asset's return (1 + r)
                        result[asset] *= (1 + returns_at_date[asset])

            # Rescale weights to sum to 1 if requested
            if rescale and result.sum() > 0:
                result = result / result.sum()

            return result

        # Use our own implementation instead of importing
        floated_returns = return_series.loc[previous_portfolio.rebalancing_date:rebalancing_date]
        floated_weights = float_weights(prev_weights, floated_returns, rescale)

        # Extract the weights of the current portfolio and align them to the union of ids
        curr_weights = curr_weights.reindex(union_ids, fill_value=0)

        # Calculate the turnover as the sum of the absolute differences between floated and current weights
        to[rebalancing_date] = (floated_weights - curr_weights).abs().sum()

    return pd.Series(to)

# %% [markdown]
# 2: Simulation
#
# (6 points)
#
# Complete the function `simulate`.

# %%
def simulate(self,
             return_series: pd.DataFrame,
             fc: float = 0,
             vc: float = 0,
             n_days_per_year: int = 252) -> pd.Series:

    rebdates = self.get_rebalancing_dates()
    ret_list = []
    for rebdate in rebdates:
        next_rebdate = (
            rebdates[rebdates.index(rebdate) + 1]
            if rebdate < rebdates[-1]
            else return_series.index[-1]
        )

        portfolio = self.get_portfolio(rebdate)
        w_float = portfolio.float_weights(
            return_series=return_series,
            end_date=next_rebdate,
            rescale=False # Notice that rescale is hardcoded to False.
        )
        level = w_float.sum(axis=1)
        ret_tmp = level.pct_change(1)
        ret_list.append(ret_tmp)

    portf_ret = pd.concat(ret_list).dropna()

    if vc != 0:
        # Calculate turnover
        to = self.turnover(return_series=return_series, rescale=False)
        # Calculate variable cost (vc) as a fraction of turnover and
        # subtract the variable cost from the returns at each rebalancing date
        for rebdate in rebdates[1:]:
            if rebdate in portf_ret.index:
                portf_ret.loc[rebdate] -= to.loc[rebdate] * vc

    if fc != 0:
        # Calculate number of days between returns
        days_between = portf_ret.index.to_series().diff().dt.days

        # Calculate daily fixed cost based on the annual fixed cost (fc),
        # the number of days per year and apply it to each day
        daily_fc = (fc / n_days_per_year)

        # Subtract the daily fixed cost from the daily returns
        portf_ret = portf_ret - daily_fc

    return portf_ret

# %% [markdown]
# Overwrite the turnover and the simulation methods of the current strategy object.

# %%
# Overwrite the turnover method of the strategy object
bt_mv.strategy.turnover = types.MethodType(turnover, bt_mv.strategy)

# Overwrite the simulate method of the strategy object
bt_mv.strategy.simulate = types.MethodType(simulate, bt_mv.strategy)

# %% [markdown]
# Calculate and plot the turnover.

# %%
bt_mv.strategy.turnover(
    return_series = data['return_series'],
    rescale = True,
).plot(title = 'Turnover', figsize = (10, 5))


# %% [markdown]
# Simulate with different cost assumptions.

# %%
return_series = bs.data['return_series']



sim_mv_gross = bt_mv.strategy.simulate(return_series=return_series, fc=0, vc=0)
sim_mv_net_of_fc = bt_mv.strategy.simulate(return_series=return_series, fc=0.01, vc=0)
sim_mv_net_of_vc = bt_mv.strategy.simulate(return_series=return_series, fc=0, vc=0.002)
sim_mv_net = bt_mv.strategy.simulate(return_series=return_series, fc=0.01, vc=0.002)


# %% [markdown]
# Plot the cumulative returns.

# %%
sim = pd.concat({
    'mv_gross': sim_mv_gross,
    'mv_net_of_fc': sim_mv_net_of_fc,
    'mv_net_of_vc': sim_mv_net_of_vc,
    'mv_net': sim_mv_net,
}, axis = 1).dropna()


np.log((1 + sim)).cumsum().plot(figsize = (10, 6))

# %% [markdown]
# 3: Descriptive Statistics
#
# (3 points)
#
# Generate a table with descriptive statistics of the simulations. Include the following statistics:
# - cumulative return (i.e., the return over the entire simulation period)
# - annualized average returns
# - annualized volatility
# - sharpe ratio
# - maximum drawdown

# %%
import empyrical as ep
# Compute individual performance metrics for each simulated strategy using empyrical
annual_return = {}
cumulative_returns = {}
annual_volatility = {}
sharpe_ratio = {}
max_drawdown = {}

for column in sim.columns:
    print(f'Performance metrics for {column}')
    annual_return[column] = ep.annual_return(sim[column])
    cumulative_returns[column] = ep.cum_returns(sim[column]).tail(1).values[0]
    annual_volatility[column] = ep.annual_volatility(sim[column])
    sharpe_ratio[column] = ep.sharpe_ratio(sim[column])
    max_drawdown[column] = ep.max_drawdown(sim[column])

# Create DataFrames for each metric
annual_returns = pd.DataFrame(annual_return, index=['Annual Return'])
cumret = pd.DataFrame(cumulative_returns, index=['Cumulative Return'])
annual_volatility = pd.DataFrame(annual_volatility, index=['Annual Volatility'])
sharpe = pd.DataFrame(sharpe_ratio, index=['Sharpe Ratio'])
mdd = pd.DataFrame(max_drawdown, index=['Max Drawdown'])

# Combine all metrics into a single DataFrame
performance_metrics = pd.concat([annual_returns, cumret, annual_volatility, sharpe, mdd])

# Display the performance metrics
performance_metrics

# %%