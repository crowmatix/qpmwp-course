{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5\n",
    "\n",
    "Deadline: 11.06.2025 12:00 CEST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task\n",
    "\n",
    "Develop an investment strategy for the Swiss equity market, backtest it using the provided datasets (`market_data.parquet`, `jkp_data.parquet`, `spi_index.csv`) and analyze its performance by benchmarking it against the SPI index. Work with the existing code infrastructure (`qpmwp-course`) and extend it by implementing any additional components needed for the strategy. Write a report that presents your methodology and the results.\n",
    "\n",
    "### Coding (15 points)\n",
    "\n",
    "- Selection:\n",
    "  Implement selection item builder functions (via `SelectionItemBuilder`) to filter stocks based on specific criteria (e.g., exclude low-quality or high-volatility stocks).\n",
    "\n",
    "- Optimization Data & Constraints:\n",
    "  Implement functions to prepare optimization data (via `OptimizationItemBuilder`), including any econometric or machine learning-based predictions. These functions should also define optimization constraints (e.g., stock, sector, or factor exposure limits).\n",
    "\n",
    "- Optimization Model:\n",
    "  If you choose to create a custom optimization model, develop a class inheriting from Optimization (similar to `MeanVariance`, `LeastSquares`, or `BlackLitterman`). Your class should include methods set_objective and solve for defining the objective function and solving the optimization problem.\n",
    "\n",
    "- Machine Learning Prediction:\n",
    "  Integrate a machine learning model to estimate inputs for the optimization, such as expected returns or risk. This could include regression, classification, or learning-to-rank models. I suggest you to use the provided jkp_data as features, but you may also create your own (e.g., technical indicators computed on the return or price series).\n",
    "\n",
    "- Simulation:\n",
    "  Backtest the strategy and simulate portfolio returns. Account for fixed costs (1% per annum) and variable (transaction) costs (0.2% per rebalancing).\n",
    "\n",
    "\n",
    "### Report (15 points):\n",
    "\n",
    "Generate an HTML report with the following sections:\n",
    "\n",
    "- High-level strategy overview: Describe the investment strategy you developed.\n",
    "\n",
    "- Detailed explanation of the backtesting steps: Offer a more comprehensive breakdown of the backtesting process, including a description of the models implemented (e.g., details of the machine learning method used).\n",
    "\n",
    "- Backtesting results:\n",
    "    \n",
    "    - Charts: Include visual representations (e.g., cumulative performance charts, rolling 3-year returns, etc.).\n",
    "    - Descriptive statistics: Present key statistics such as mean, standard deviation, drawdown, turnover, and Sharpe ratio (or any other relevant metric) for the full backtest period as well as for subperiods (e.g., the last 5 years, or during bull vs. bear market phases).\n",
    "    - Compare your strategy against the SPI index.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import sys\n",
    "import types\n",
    "\n",
    "# Third party imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Add the project root directory to Python path\n",
    "# Load environment variables from .env file\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "src_path = os.getenv('PROJECT_SOURCE_DIR')\n",
    "#print(src_path)\n",
    "sys.path.append(src_path)\n",
    "\n",
    "# Local modules imports\n",
    "from helper_functions import load_data_msci\n",
    "from estimation.covariance import Covariance\n",
    "from estimation.expected_return import ExpectedReturn\n",
    "from optimization.optimization import MeanVariance\n",
    "from backtesting.backtest_item_builder_classes import (\n",
    "    SelectionItemBuilder,\n",
    "    OptimizationItemBuilder,\n",
    ")\n",
    "from backtesting.backtest_item_builder_functions import (\n",
    "    bibfn_selection_data_random,\n",
    "    bibfn_return_series,\n",
    "    bibfn_budget_constraint,\n",
    "    bibfn_box_constraints,\n",
    ")\n",
    "from backtesting.portfolio import floating_weights\n",
    "from backtesting.backtest_service import BacktestService\n",
    "from backtesting.backtest import Backtest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        date id    return  market_return\n",
      "0 1999-05-06  1       NaN      -0.005188\n",
      "1 1999-05-07  1 -0.013015      -0.001979\n",
      "2 1999-05-10  1  0.000000       0.001216\n",
      "3 1999-05-11  1  0.010989      -0.001575\n",
      "4 1999-05-12  1  0.000000      -0.004866\n",
      "5 1999-05-14  1  0.000000      -0.011553\n",
      "6 1999-05-19  1  0.000000       0.002712\n",
      "7 1999-05-21  1  0.000000      -0.006180\n",
      "8 1999-05-26  1  0.000000       0.001580\n",
      "9 1999-05-31  1  0.006522       0.015358\n"
     ]
    }
   ],
   "source": [
    "## 1. Load Data\n",
    "market_data = pd.read_parquet('../data/market_data.parquet')\n",
    "jkp_data = pd.read_parquet('../data/jkp_data.parquet')\n",
    "# Load spi_index.csv with correct column names and date parsing\n",
    "spi_index = pd.read_csv(\n",
    "    '../data/spi_index.csv',\n",
    "    names=['date', 'spi'],\n",
    "    header=0,\n",
    "    parse_dates=['date'],\n",
    "    dayfirst=True\n",
    ")\n",
    "\n",
    "# Check for date and ticker columns in market_data\n",
    "#print(market_data.head())\n",
    "#print(market_data.index.names)\n",
    "\n",
    "# If date/ticker are in the index, reset them to columns\n",
    "if 'date' not in market_data.columns or 'ticker' not in market_data.columns:\n",
    "    market_data = market_data.reset_index()\n",
    "    #print(market_data.columns)\n",
    "    #print(market_data.head())\n",
    "\n",
    "# Compute daily returns for each stock\n",
    "market_data = market_data.sort_values(['id', 'date'])\n",
    "market_data['return'] = market_data.groupby('id')['price'].pct_change()\n",
    "\n",
    "# Inspect the result\n",
    "#print(market_data[['date', 'id', 'price', 'return']].head(10))\n",
    "\n",
    "# Merge market return (SPI) into market_data\n",
    "market_data = pd.merge(\n",
    "    market_data,\n",
    "    spi_index.rename(columns={'spi': 'market_return'}),\n",
    "    on='date',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "print(market_data[['date', 'id', 'return', 'market_return']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'RollingRegressionResults' object has no attribute 'resids'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33midio_vol\u001b[39m\u001b[33m'\u001b[39m] = df.groupby(\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mresid\u001b[39m\u001b[33m'\u001b[39m].rolling(window).std().reset_index(\u001b[32m0\u001b[39m, drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m market_data = \u001b[43mcompute_idio_vol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmarket_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Inspect result\u001b[39;00m\n\u001b[32m     23\u001b[39m \u001b[38;5;28mprint\u001b[39m(market_data[[\u001b[33m'\u001b[39m\u001b[33mdate\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mreturn\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mmarket_return\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33midio_vol\u001b[39m\u001b[33m'\u001b[39m]].dropna().head(\u001b[32m10\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mcompute_idio_vol\u001b[39m\u001b[34m(df, window)\u001b[39m\n\u001b[32m     13\u001b[39m     res = rols.fit()\n\u001b[32m     14\u001b[39m     \u001b[38;5;66;03m# Use .resids for residuals\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m     df.loc[stock.index, \u001b[33m'\u001b[39m\u001b[33mresid\u001b[39m\u001b[33m'\u001b[39m] = \u001b[43mres\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresids\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# Rolling std of residuals = idiosyncratic volatility\u001b[39;00m\n\u001b[32m     17\u001b[39m df[\u001b[33m'\u001b[39m\u001b[33midio_vol\u001b[39m\u001b[33m'\u001b[39m] = df.groupby(\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m)[\u001b[33m'\u001b[39m\u001b[33mresid\u001b[39m\u001b[33m'\u001b[39m].rolling(window).std().reset_index(\u001b[32m0\u001b[39m, drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[31mAttributeError\u001b[39m: 'RollingRegressionResults' object has no attribute 'resids'"
     ]
    }
   ],
   "source": [
    "## 2. Compute Idiosyncratic Volatility\n",
    "from statsmodels.regression.rolling import RollingOLS\n",
    "\n",
    "def compute_idio_vol(df, window=252):\n",
    "    df = df.copy()\n",
    "    df['resid'] = np.nan\n",
    "    for ticker in df['id'].unique():\n",
    "        stock = df[df['id'] == ticker]\n",
    "        if len(stock) < window:\n",
    "            continue\n",
    "        # Rolling regression: return ~ market_return\n",
    "        rols = RollingOLS(stock['return'], stock[['market_return']], window=window)\n",
    "        res = rols.fit()\n",
    "        # Use .resids for residuals\n",
    "        df.loc[stock.index, 'resid'] = res.resids\n",
    "    # Rolling std of residuals = idiosyncratic volatility\n",
    "    df['idio_vol'] = df.groupby('id')['resid'].rolling(window).std().reset_index(0, drop=True)\n",
    "    return df\n",
    "\n",
    "market_data = compute_idio_vol(market_data)\n",
    "\n",
    "# Inspect result\n",
    "print(market_data[['date', 'id', 'return', 'market_return', 'idio_vol']].dropna().head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
